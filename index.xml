<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Alex J. Hope on Alex J. Hope</title>
    <link>https://ehhope.github.io/</link>
    <description>Recent content in Alex J. Hope on Alex J. Hope</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0600</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>MDS Block 3</title>
      <link>https://ehhope.github.io/post/mds-block-3/</link>
      <pubDate>Tue, 25 Dec 2018 01:53:01 -0700</pubDate>
      
      <guid>https://ehhope.github.io/post/mds-block-3/</guid>
      <description>&lt;p&gt;My experience and thoughts on block 3 of MDS at UBC. The courses were: DSCI 513, DSCI 522, DSCI 561, and DSCI 571.&lt;/p&gt;

&lt;h2 id=&#34;introduction-to-block-3&#34;&gt;&lt;strong&gt;Introduction to Block 3&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;This post comes to you after finishing block 3 of MDS, the final block of 2018. What a month it was! I think I speak for everyone in the program and say this was the most intellectually challenging yet gratifying work in the degree thus far. Quite simply, you can start to see the power behind what you are learning in classes like Supervised learning (DSCI 571) and Workflows (DSCI 522) and the importance of having instructors curate content that understand it deeply and know what you need to focus on and what you don&amp;rsquo;t. Any student that went through this block can tell you about the basics of linear regression, how relational and semi-structured databases work, how to apply different machine learning algorithms for different problems and the pros/cons of each, as well as how to automate scripts that span the analysis process (wrangling, visualization, analysis and communication). It felt like we were starting to dig into the material that brought me here in the first place, and the content that was the real value I could offer an employer on the other side of this master&amp;rsquo;s program. Without further delay, each class from block 3.&lt;/p&gt;

&lt;h3 id=&#34;supervised-learning-dsci-571-dr-mike-gelbart&#34;&gt;&lt;strong&gt;Supervised Learning (DSCI-571: Dr. Mike Gelbart)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Heading into this class I was a bit intimidated looking at the material. Anyone with an interest in data science has heard of sci-kit learn, machine learning, overfitting and underfitting, but I also knew these could be incredibly complex concepts that were not easy to unpack let alone in 4 weeks. To my surprise, I learned more in this class than any other I&amp;rsquo;ve taken in this degree, hands down. Mike Gelbart delivered a &amp;ldquo;flipped&amp;rdquo; classroom style course where before each lecture we were asked to watch a video on a specific machine learning classifier that we would then cover in lecture. The opportunity to absorb information prior to lecture was a huge help in scaling my learning, and allowed me to go deeper into the concepts we covered in lecture as a result. Mike&amp;rsquo;s examples and notes were extremely clear and helpful, and when paired with the labs I could see the power of the sci-kit library and how many of the classifiers could be applied to a range of datasets from music rankings (Spotify), voting patterns in political elections (Democrat vs Republican), to natural language processing (IMDB Movie Reviews), just to name a few. We also covered critical concepts like cross-validation, balancing your training and test error and how determining the &amp;lsquo;accuracy&amp;rsquo; of a given model isn&amp;rsquo;t always as straight-forward as it may seem. Any student leaving this class is capable of: applying machine learning algorithms with the fundamental trade-off of selecting hyperparameters kept in mind, and understanding what algorithms may be best for classification or regression problems.&lt;/p&gt;

&lt;p&gt;There is so much to learn in this area and while it feels like we&amp;rsquo;ve still scratched the surface on how different algorithms actually work underneath the hood (math and assumptions represented as code within each function) and perform under certain conditions with different kinds of data, it taught me that these topics don&amp;rsquo;t have to be intimidating to get into. In fact, if you focus on a high-level understanding of what&amp;rsquo;s happening when an algorithm is fit to data and predicts on new data and consider WHY some algorithms may be more effective than others at this process, you can walk away with a great foundation of machine learning fundamentals. For anybody whose new to concepts in data science, there can be a sense of fear in students when confronting machine learning courses and understandably so because they are indeed complex topics. While there are a plethora of materials available out there to learn on your own and it has never been easier, what really made MDS worth it is to know &lt;strong&gt;what to learn within ML&lt;/strong&gt;, in &lt;strong&gt;what order&lt;/strong&gt; to best digest the info, and to have someone take you through simple examples of &lt;strong&gt;how it can be applied&lt;/strong&gt; and present important concepts to you in a way that are gradual to help build your intuition and grasp of the information.&lt;/p&gt;

&lt;p&gt;With that in mind, I have to thank Mike and Varada (Head TA) for designing this curriculum in a way that was extremely digestible. I had heard rumours that DSCI 571 was quite difficult for the previous cohort and I think they both took this to heart in designing the curriculum and labs this year, hats off to them. I also consistently got the impression they cared about the success of students in the course, and would do whatever is needed to help you understand concepts whether its extending or adding office hours, recommending new materials or addressing slack questions promptly.&lt;/p&gt;

&lt;p&gt;For any future students, coursework like this is likely a core reason why you are applied to MDS, and I can happily say it is also where you will feel like you&amp;rsquo;re growing the most in this degree and I&amp;rsquo;m glad I feel I made the most of this opportunity.&lt;/p&gt;

&lt;h3 id=&#34;data-science-workflows-dsci-522-dr-tiffany-timbers&#34;&gt;&lt;strong&gt;Data Science Workflows (DSCI-522: Dr. Tiffany Timbers)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;This class was interesting because it was the first of it&amp;rsquo;s kind up until now for this year&amp;rsquo;s MDS cohort. While I had heard issues raised from some students in my cohort about fixed group work for the entirety of the course, I found it to be a great experience with my group partner. The group work was one unique aspect but it also did not have any exams or labs, only project deadlines each week that asked us to apply what we had learned in lecture regarding script automation and containerization to our project. My partner and I chose an NBA dataset where we applied our supervised learning skills (decision tree classifier) to try and predict whether a shot would be made or missed by Lebron James, and automate our wrangling, exploratory visualization and analysis process. It was an interesting blend of many of the skills we acquired in block 2 regarding visualizations, wrangling as well as the block 3 machine learning skills we cultivated.&lt;/p&gt;

&lt;p&gt;The real focus of the course wasn&amp;rsquo;t reiterating these skills that we had already acquired though, it was using tools like &lt;code&gt;Make&lt;/code&gt; and &lt;code&gt;Docker&lt;/code&gt; to automate these processes and encapsulate them in containers that are reproducible across platforms. I intend on applying them to all of my projects in the future since once the framework is built they can deliver faster, more flexible results. For instance, my partner had an ingenius idea to take our project a step further in automating our scripts based on a keyword argument so that when we ran the scripts and provided a &amp;lsquo;player name&amp;rsquo; argument, you could run the full report for any player in the NBA you wanted, not just Lebron James. Now you can wrangle, visualize, and analyze characteristics of shots from any player in the NBA and compute these scripts in under a few seconds. Amazing!&lt;/p&gt;

&lt;p&gt;My hope is that in the future I can use Make and Docker to build more complex and flexible scripts than the project we built, perhaps a larger analysis pipeline to address questions that interest me and allow me to come back and run new ideas through a pipeline that I think may be interesting. Once the pipeline is built, as long as you are feeding it data that is structured to fit your code, you can generate results in very little time and that seems like a valuable investment for future work with similar datasets and approaches. I highly recommend becoming acquainted with script automation and firmly stand by the belief that it is worth it to invest yourself in this class. If you&amp;rsquo;re working within a larger company when you graduate, there is a very good chance that they will have large pipelines in place already, and you will be asked to take advantage of these in your work. It will save you a ton of time and energy, and you&amp;rsquo;ll be more productive in the long run. So dive in!&lt;/p&gt;

&lt;p&gt;Tiffany&amp;rsquo;s teaching style really shines through in courses where there&amp;rsquo;s a lot of in-class coding and actionable instructions to follow in lecture. Her strength as an instructor is taking various packages and platforms that are complex and showing students in a step-wise fashion how the basics actually work. She is great at helping you realize this doesn&amp;rsquo;t have to be so complicated. Every lecture Tiffany also gives us a 5-minute break and plays music, which was an unexpected but greatly appreciated mental break. I know she is mindful of our workload and stress levels, even with the little things like this. Some students had issues with their partner or some aspect of the group work but for myself, it was a great experience where I could learn lots from both Tiffany and my partner but also not sweat looming deadlines of labs or exams for the class. This helped with balancing labs and exams for the other classes as well.&lt;/p&gt;

&lt;p&gt;For anyone interested in the NBA project my partner and I worked on for this class, it can be found on GitHub here: &lt;a href=&#34;https://github.com/ehhope/LBJ-for-Tree&#34; target=&#34;_blank&#34;&gt;Lebron James for T(h)ree!&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;regression-i-dsci-561-dr-gabriela-cohen-frue&#34;&gt;&lt;strong&gt;Regression I (DSCI-561: Dr. Gabriela Cohen-Frue)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Heading into this class, I knew exactly what to expect and that it wouldn&amp;rsquo;t be easy for me. I had encountered linear regression in one of my past positions in mental health research, but admittedly, did not fully understand the ins-and-outs of what I was assuming and had generally struggled through statistics classes in my undergrad. Undoubtedly, I worked the hardest in this class to understand the material, but I can only imagine how much harder it would have been if Gabriela had not been our instructor. I thought this class moved at a reasonably slow pace, where we really focused on the core components of simple and multiple linear regression across 7 of the 8 weeks. Gabriela re-iterated many themes in this class at both the theoretical level with respect to the thinking behind concepts such as cell-means versus reference-treatment parameterization, errors vs residuals and least squares fitting, but also how this was expressed in R&amp;rsquo;s output.&lt;/p&gt;

&lt;p&gt;Ultimately as data scientists we will be working with a programming language that computes many of these statistical measures, and so the burden of understanding falls more on the side of using R&amp;rsquo;s functions and interpreting their output than explicitly calculating the measures and remembering formulas. I thought in general she balanced these demands quite well, but think she could stray a bit further from the calculus aspects of how certain measures are calculated and get back to R. I really wanted a deeper discussion of the direct R output and the higher-level forms of the concepts we were discussing like multicollinearity, and the coefficient of determination, among others. With only 4 weeks to learn regression spending a lecture or two on the calculus behind formulas simply isn&amp;rsquo;t productive in my opinion. However, in general she is a wonderful instructor with an intimate understanding of statistics that can&amp;rsquo;t be understated. Ask a ton of questions in this class, I promise you&amp;rsquo;re not alone in wondering what that standard error formula means, how to manage outliers, or different forms of fitting regression models. This is no fault of the instructor, statistics is a slippery fish of knowledge that takes a lot of effort and attention to not only understand but apply properly. The more questions you ask and the more you can remain patient in your learning, the firmer the grasp you will have on this statistical fish.&lt;/p&gt;

&lt;p&gt;I thought Vincenzo (TA) did a solid job with the lab design as well, gradually building our intuition of how regression truly worked while challenging us to consider what the output of &lt;code&gt;lm&lt;/code&gt; vs &lt;code&gt;anova&lt;/code&gt; vs &lt;code&gt;aov&lt;/code&gt; really meant. Overall, this course was a pleasant surprise given my past struggles in statistics. Gabriela and Vincenzo will help you see the value in understanding these concepts as they will undoubtedly arise in an analytics career. Examining relationships between data, fitting linear models and making predictions about future observations are all critical skills in an analysts toolbox, choose to cultivate them!&lt;/p&gt;

&lt;h3 id=&#34;databases-and-data-retrieval-dsci-513-bhav-dhillon&#34;&gt;&lt;strong&gt;Databases and Data Retrieval (DSCI-513: Bhav Dhillon)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Heading into this class I had no experience with SQL or really any relational or semi-structured databases and while I did finish with a reasonable understanding of the materials, this class left a fair bit of room for improvement. A common trend I am noticing within the degree is that the classes with instructors who are furthest removed from the computer science/MDS/statistics faculty tend to be the worst from an educational standpoint. I don&amp;rsquo;t necessarily say this with respect to their ability as an instructor because I don&amp;rsquo;t think that&amp;rsquo;s the case at all, in fact they have been very talented and driven instructors. What I mean is it&amp;rsquo;s harder to integrate material from the lecture into the labs and draw from past successes in other classes that may be useful for the instructor if they communicate less with the core faculty that curates the overall curriculum. This gap in communication reflected itself in general student engagement, and concept acquisition in DSCI 513. The instructor was a post-doc brought in to teach DSCI-513 and who was not embedded within the overarching educational picture of the program and was not familiar with the content we had already learned that may inform their teaching (ex. inner joins, select, etc.). Bhav was brought in to teach this specific class and the lectures were quite poorly laid out with respect to how they integrated with labwork, plain and simple. That said, she was kind, knowledgeable and always available for help and was much more effective one on one with students I found. Again, I don&amp;rsquo;t think it&amp;rsquo;s a reflection of her abilities at all, simply an organizational critique. The overarching concepts were laid out by Bhav and while the early lectures seemed to confuse her at times along with the students, by the end they were clear and more useful given that we hadn&amp;rsquo;t encountered the later concepts in previous courses.&lt;/p&gt;

&lt;p&gt;Every student can tell you about primary and foreign keys in databases, and ER diagrams for different forms of relationships between information. That said, I can&amp;rsquo;t help but feel like this class still left lots to be desired. It should have been what data wrangling (DSCI-523) was but with SQL/JSON and it just didn&amp;rsquo;t live up to that standard. An additional issue was having to use SQLite, which is not really a common language in the working world despite it&amp;rsquo;s syntactical similarities to MySQL, the more common language. Again, the reason for this is UBC does not have an infrastructure in place for relational databases so we were forced to use SQLite. In my opinion, organization would go a long way in improving this class not necessarily changing the instructor or the material itself per se.&lt;/p&gt;

&lt;p&gt;Without being a huge downer, I still learned lots from this class, and Rodolfo (TA) challenged us in the labs which forced me to get creative with my learning. The majority of my breakthroughs in lab work came through trial-and-error and referencing alternative resources beyond lecture notes to develop the necessary understanding to get through difficult questions. Having to go that extra mile elevated my thinking around how to work with databases, the best ways to design them given particular constraints, and I improved drastically at visualizing different kinds of joins between separate tables! So I guess I have that going for me. In sum, I hope for next year they find ways to improve upon this course structurally, and increase the communication between core faculty and the course instructor regarding what concepts we may have already covered. I still was able to learn a ton about databases, it just took more energy given the constraints I&amp;rsquo;ve mentioned but if you&amp;rsquo;re motivated, you&amp;rsquo;ll be just fine.&lt;/p&gt;

&lt;h3 id=&#34;closing-thoughts-suggestions&#34;&gt;&lt;strong&gt;Closing Thoughts &amp;amp; Suggestions&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Block 3 was by far the most action packed block regarding the density of material and the most exciting given the power of what we were learning. Generally speaking I have great things to say about the teaching staff in this block, I know far more than I did a month ago and don&amp;rsquo;t see myself forgetting the core materials in each class because they were so fundamental. Linear models, machine learning algorithms for classification and regression, how relational databases work via keys and constraints, and script automation are such valuable bodies of knowledge for a data scientist, analyst or really anyone working with data. Aside from some structural issues with one course and the recurring fact that I just don&amp;rsquo;t have enough time to go into everything that intrigues me, this was a great 4 weeks.&lt;/p&gt;

&lt;h3 id=&#34;additional-ideas-recommendations&#34;&gt;&lt;strong&gt;Additional Ideas/Recommendations&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;One idea that came to me while working in this block is for the wrangling and database classes or really any class that requires more technical skill is to provide a &amp;lsquo;puzzle dataset&amp;rsquo; to students at the start of the block that has various manipulations and is considered &amp;lsquo;untidy&amp;rsquo;. As students learn the skills for a course (perhaps multiple courses) they will be able to apply it to this puzzle dataset and at the end possess all the skills to actually solve it. They can then reference a key that the TA has, and it provides some optional work for students to get practice and tackle optional problems. Obvious classes where this can be implemented are 523 with R (dplyr) and 513 (SQL) but any course where instructors feel they can offer a big picture assignment that students can tackle might be a nice addition to the regular lab work. This could be extended to questions where a dataset must be wrangled and a linear model must be fitted to some portion of the data once it is tidied, incorporating multiple classes and areas of understanding to resolve the problem. It also comes at very little cost to the TA&amp;rsquo;s because the head TA is designing databases to be worked with already by the students, and provides one more large project the students can grade themselves by comparing with a key.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>MDS Block 2</title>
      <link>https://ehhope.github.io/post/mds-block-2/</link>
      <pubDate>Tue, 25 Dec 2018 01:43:24 -0700</pubDate>
      
      <guid>https://ehhope.github.io/post/mds-block-2/</guid>
      <description>&lt;p&gt;My experience and thoughts on block 2 of MDS at UBC. The courses were: DSCI 512, DSCI 523, DSCI 531, and DSCI 552.&lt;/p&gt;

&lt;h2 id=&#34;introduction-to-block-2&#34;&gt;&lt;strong&gt;Introduction to Block 2&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;I want to break down my thoughts for this block course by course because I have a lot to say, and it doesn&amp;rsquo;t neatly cut across topics, not to mention, my experiences with courses in this block were quite different. First, a few general thoughts before I dive in. I got the most out of courses that I invested myself in, plain and simple. While that seems like a common trope, it really holds true in data wrangling, and algorithms &amp;amp; data structures where the degree of difficulty is quite high in the content, and the lecturer is forced to feed you complex material quickly given the time constraints. The content in a couple courses was quite difficult, and I found myself scrambling two of the four weeks to get my labs in despite putting a ton of effort into my labs. Learning these skills and forms of thinking requires considerable persistence, and for that reason I was ok with barely finishing. This material is &lt;strong&gt;&lt;em&gt;supposed&lt;/em&gt;&lt;/strong&gt; to be difficult! That&amp;rsquo;s the point! So with that expressed let me talk about each class.&lt;/p&gt;

&lt;h3 id=&#34;algorithms-and-data-structures-dsci-512-patrice-belleville&#34;&gt;&lt;strong&gt;Algorithms and Data Structures (DSCI-512: Patrice Belleville)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;This was undoubtedly the most difficult course of the block, and the concepts were at times challenging to grasp. The reason they were hard to follow was primarily because of the speed of the curriculum where we would cover hash tables in 25% of one lecture, and touch on different forms of search trees for the rest of lecture before diving into a single lecture on various kinds of directed and undirected graphs. The material was complex but still digestible, and Patrice was a strong instructor, but the time constraints placed a significant burden on people&amp;rsquo;s learning where there was a tendency to learn to get through the course rather than learn to absorb the material of the course for future reference. When the material scales up significantly in difficulty, this was a common feeling in students and I certainly felt it at times as well. For perspective on the pace, undergraduates will spend an entire semester or two examining the full range of material we covered in a single month. This is not only a huge challenge for students, but also the instructor to curate the material and emphasize what is only crucial while discarding or grazing briefly on an area.&lt;/p&gt;

&lt;p&gt;In addition to the pace, there was a huge gap between the lecture material and the questions being asked in labs where the content we covered needed to be implemented but in a way that was far beyond the coding ability of most of the cohort. Given the general class response I knew I wasn&amp;rsquo;t alone in struggling to apply my understanding of recursion to sierpinski&amp;rsquo;s triangle, or image resizing, but I also secretly enjoyed confronting this massive challenge. This was not an easy introduction to algorithms and how they are implemented in data structures, and I need to learn more on these topics after finishing this class to round out my learning given their importance in data science, but I felt it was more of a structural issue with the disconnect between lecture material and lab material than Patrice&amp;rsquo;s poor teaching that really left me with this impression.&lt;/p&gt;

&lt;p&gt;To excel in this class you need a strong familiarity with object oriented programming, and should possess an aptitude for reading code that is likely more complex than you can write at this stage. I saw this class as a tough challenge that elevated my thinking on the topic, but didn&amp;rsquo;t provide enough scaffolding to really help me understand the mechanics of how every algorithm worked or how they were implemented in different problems in the labs such as with facebook data that was provided in one lab. That said, if you listen in class you will walk away with an understanding of breadth-first vs depth-first search trees and how they are represented in python. And the different forms of searching whether with rote methods or through recursion. In addition, we spent considerable time looking at how different kinds of graphs can represent information about individual entities, as well as the relationships between these entities. In some cases they were bi-directional and others they were uni-directional depending on the flow of information. The big picture here was, if we wanted to model an algorithm after a particular social media site, or scheduling problem, what would we choose? This high-level planning requires you to know the details about how information is exchanged, referenced and what graphs will and will not allow as far as the flow of that data.&lt;/p&gt;

&lt;p&gt;This class really could&amp;rsquo;ve been more effective if it had students with a higher coding literacy, and I would beg the instructors to consider scaling up the intro coding classes in block 1 to cover OOP in greater depth and have students write functions sooner in DSCI 511 so they can approach difficult questions in labs with greater confidence. Having to learn to code on top of understanding the algorithms can be daunting, and it would serve all parties involved to make this change I think.&lt;/p&gt;

&lt;p&gt;While it seems like I have a lot to say that&amp;rsquo;s negative, part of being a student is also embracing challenge and uncertainty. I learned a lot in this class because I felt like I had to in order to do well, and that pushed me to invest more of myself in it than other classes where I felt it was easier to grab the content quickly and implement the knowledge. Here, I had no choice but to study hard, and that&amp;rsquo;s what being a graduate student is all about&amp;hellip;.. digging deeper.&lt;/p&gt;

&lt;h3 id=&#34;data-wrangling-dsci-523-jenny-bryant&#34;&gt;&lt;strong&gt;Data Wrangling (DSCI-523: Jenny Bryant)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Data wrangling is a fundamental skill in data science, and that is a fact. A significant portion of your time as an analyst will be spent simply preparing a dataset for analysis and deep exploration. Whether it&amp;rsquo;s changing the type of data in columns, creating 2 columns out of information contained in a single column, creating columns that are aggregates of other columns, joining different tables together, or simply grouping variables together to extract meaning in ways that are not fully apparent until they are grouped by their factor, data wrangling really matters and it won&amp;rsquo;t take you long to see why. I enjoyed this class the most of any course in the block and perhaps to date in this degree. It was difficult and frustrating at times banging my head against a problem that required multiple joins or a function I wasn&amp;rsquo;t used to applying like &lt;code&gt;lag&lt;/code&gt;. Let&amp;rsquo;s just say I had to take many breaks from the computer to finish these labs but out of this immense frustration was an extreme sense of reward when I would learn to parse data in that column, or adjust the time with respect to timezone, or just manipulate data how I intended. I felt powerful, and these are pivotal skills you need to know. Having no experience in R prior to this degree, I couldn&amp;rsquo;t imagine a smoother experience wrangling than with the &lt;code&gt;Tidyverse&lt;/code&gt;. It&amp;rsquo;s reputation exists for a reason, it&amp;rsquo;s straight forward and sensical to people looking to wrangle data and Jenny Bryant (our instructor) had a big part in the development and maintenance of this package.  Most of all, it felt like I was really learning a tangible skill that is readily applicable to projects I wanted to work on in my spare time. Along with visualization, it instilled a feeling that I could start to hit the ground running on projects and make reasonable progress working with any data I encountered. The course also provided immediate feedback to me on my abilities and I found that to be quite reinforcing in a way that a class like probability or algorithms was not. As far as Jenny Bryant, her reputation also speaks for itself. She is a world class instructor with quality lecture materials, resources and humor to charm any student she educates and I know the cohort genuinely found her lectures to be intriguing, helpful, and balanced in their difficulty. It was a pleasure to have her for this class and reassuring that someone heavily involved in the maintenance of the &lt;code&gt;Tidyverse&lt;/code&gt; was teaching us how to use it.&lt;/p&gt;

&lt;p&gt;You may be thinking well wait&amp;hellip;. what about Python? We covered Python&amp;rsquo;s &lt;code&gt;Numpy&lt;/code&gt; and &lt;code&gt;Pandas&lt;/code&gt; in one class taught by Mike Gelbart, which in my opinion deserved a second lecture given how much Python will be used in ML blocks coming up but mainly focused on R in this class. I believe the thinking was that we could always wrangle in R prior to analyzing in python and while that is fair, python is such a prominent language it would be nice to attend to it&amp;rsquo;s wrangling libraries as well. Admittedly, I didn&amp;rsquo;t really learn anything new in this lecture simply because I knew the Pandas library quite well already. Nonetheless, I am much more confident in my wrangling abilities and genuinely enjoy the challenge of shaping the dataset how I&amp;rsquo;d like.&lt;/p&gt;

&lt;p&gt;For anyone taking this class, you will be well acquainted with how to join different datasets based on particular keys and the type of join you want, how to select particular information in a dataframe, what a tibble is compared to a dataframe, how to add columns, delete data and replace NA&amp;rsquo;s. All of these things are important skills to possess, and I felt for the month we spent wrangling, we covered this material very well. I banged my head on the practice problems enough that the material was seamlessly drilled into my head, and it was so worth it. This is a skill anybody working with data will continue to use moving forward.&lt;/p&gt;

&lt;h3 id=&#34;visualization-i-dsci-531-vincenzo-coia&#34;&gt;&lt;strong&gt;Visualization I (DSCI 531: Vincenzo Coia)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;In general, I thought Vincenzo did a great job with this class. He took us through basic graph theory as far as what various plots convey in their variables and information, but also gradually taught us the relevant syntax for ggplot, which has become a personal favourite for visualizing data. Also, graphing data to gather a sense of patterns is under appreciated and not talked about enough. A common mistake is to want to start analyzing immediately and rely on visualizations for their final results to convey information, but Vincenzo really taught me a lot about patience and understanding data through graphs PRIOR to starting any analyses. Get to know what you are working with! Similar to wrangling, we were only introduced to Matplotlib (Vincenzo) in one lecture and Seaborn (Chris- TA) in another lecture. I got a lot out of the Seaborn lecture from Chris, and was relieved to see visualizations in Python can be as easy as in R, but would have loved to see a bit more with respect to python here.&lt;/p&gt;

&lt;p&gt;Overall, Vincenzo is a fantastic post-doc who is extremely knowledgeable in R and can convey the basics of graphing extremely well. The only recommendation I have for him as an instructor is to consider a lecture through the lens of a new analyst that wants to understand relationships in the data they have. How can they go about this graphically? What should they look for in the data, what plots should they try, how many different graphs should they plot to get a sense of any patterns? Some form of exploratory thinking would go a long way in adding substance to the syntax we learned. Other than that though it was a great lecture and whether you have the intuition to explore data or not, anyone who took this class can write the syntax to accomplish what they need.&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;ll know what kinds of information bar graphs, scatterplots, pie graphs, box plots, word clouds, and map graphs represent and what variables are required to create these visualizations. Also, you&amp;rsquo;ll learn about the ingredients of graphs, so what is the x and y-axis? Are the scales on a log, or normal axis? Can you facet by a certain group to convey multiple plots within a single graph that are separated by group? These sorts of considerations are all touched on intelligently in lecture, and you&amp;rsquo;ll feel comfortable graphing anything basic that you need by the end. Looking forward to seeing what Data Visualization II has in store for us.&lt;/p&gt;

&lt;h3 id=&#34;statistical-inference-i-dsci-552-tiffany-timbers&#34;&gt;&lt;strong&gt;Statistical Inference I (DSCI 552: Tiffany Timbers)&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;First, Tiffany teaches clearly and crisply with great lecture examples that offer insight into her labs directly. She&amp;rsquo;s also a dynamic instructor that is engaging and it definitely helped with holding my attention on a topic that doesn&amp;rsquo;t exactly grab you at first glance. Bootstrapping is a powerful method for inferring about the meaning of a sample by generating thousands of samples and comparing it&amp;rsquo;s test statistic with those of the other samples that have bootstrapped in the form of a distribution. While the relevant test statistic you are calculating and assumptions with a t-distribution (CLT) was nothing new, I still learned the syntax for t-tests, confidence intervals and p-values through &lt;code&gt;R&lt;/code&gt;&amp;rsquo;s &lt;code&gt;infer&lt;/code&gt; package. It was nice to run over basic stats with Tiffany, and learn about applying bootstrapping as a technique in R, but I also recognize the need for more practice to hammer in these concepts on real live datasets where I&amp;rsquo;m generating my own null/alternative hypotheses and running t-tests and anova&amp;rsquo;s.&lt;/p&gt;

&lt;p&gt;Any student that finished this class can tell you what a p-value is and what it signifies with respect to a z-score or t-value in the context of a normal distribution, and what assumptions about normality and standard error exist. Overall, this was a solid class that was a helpful review and introduced us to how R can make our lives infinitely easier once we understand the theory.&lt;/p&gt;

&lt;h3 id=&#34;closing-thoughts-on-block-2&#34;&gt;&lt;strong&gt;Closing Thoughts on Block 2&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;My overall impression was positive here, there were far more great moments where I felt absorbed by what I was learning than awful ones where I&amp;rsquo;m overwhelmed but I&amp;rsquo;d be lying if I said this was an easy block. The feeling of drowning in information is part of diving into a new area, let alone one that is extremely complex, new as a field, and constantly evolving like data science. Block 2 definitely felt like a deeper dive into new territory and you can tell the material has started to take an upward incline in difficulty but I felt like I rose to the occasion and as the difficulty increases you can really start to see the value in what you&amp;rsquo;re learning and how it can be applied. This is itself quite motivating, and definitely helps you see the finish line. I grew so much with R in this block, despite having serious doubts about it as a language that I would enjoy using. Now, &lt;code&gt;ggplot&lt;/code&gt;, and &lt;code&gt;dplyr&lt;/code&gt; have completely changed my mind and I will happily use the Tidyverse for future work.&lt;/p&gt;

&lt;p&gt;At a broader level, the terrain this block feels like an initial entree for data science, and looking at the block 3 course curriculum I&amp;rsquo;ll be curious to see how things progress to the main dishes with regression and machine learning. One major piece that continues to stick with me is the time of this degree. If this degree was even 6 weeks longer and the curriculum was the same, I think everything would feel a bit less rushed and I&amp;rsquo;d have the time to fully absorb what I&amp;rsquo;m doing. Don&amp;rsquo;t get me wrong, I am learning a ton, but anytime you try and integrate as much info as this degree demands, you are bound to forget things along the way if it is not used. It&amp;rsquo;s an inevitable downside to the human brain, but that said I&amp;rsquo;m glad I&amp;rsquo;ve squeezed what I could and as it stands I feel like I know the material extremely well.&lt;/p&gt;

&lt;p&gt;What a month it was and onto the next block we go! Until next time&amp;hellip;.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>BRIEF Intervention</title>
      <link>https://ehhope.github.io/project/brief-intervention/</link>
      <pubDate>Sun, 23 Dec 2018 03:15:12 -0700</pubDate>
      
      <guid>https://ehhope.github.io/project/brief-intervention/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NBA Shot Classifier</title>
      <link>https://ehhope.github.io/project/nba-shot-decision-tree/</link>
      <pubDate>Sun, 23 Dec 2018 01:26:14 -0700</pubDate>
      
      <guid>https://ehhope.github.io/project/nba-shot-decision-tree/</guid>
      <description>

&lt;h3 id=&#34;decision-tree-analysis-of-makes-misses-in-the-nba&#34;&gt;Decision Tree Analysis of Makes &amp;amp; Misses in the NBA&lt;/h3&gt;

&lt;h6 id=&#34;a-case-study-lebron-james&#34;&gt;A case study: Lebron James&lt;/h6&gt;

&lt;p&gt;This &lt;a href=&#34;https://github.com/ehhope/LBJ-for-Tree&#34; target=&#34;_blank&#34;&gt;project&lt;/a&gt; focuses on the 2014-2015 NBA season with a dataset containing characteristics of every shot (shot distance, defender, shot clock, etc.) taken by every player in the NBA. The approach used a decision tree classifier to predict whether a shot was made or missed based on shot features for each shot taken by the player. Lebron James season with the Cleveland Cavaliers was used as a case example, however, the script is flexible enough to wrangle, visualize with several plots, analyze and report data for any player if specified as an argument when using &lt;code&gt;make&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Our decision tree classifier predicted Lebron James at a marginal ~65% when hyperparameters were optimized, however, other players we were able to score upwards of 85%. The reason for the model&amp;rsquo;s poor accuracy with Lebron James, Steph Curry, and other top shooters is that the features don&amp;rsquo;t segregate makes/misses as cleanly as players who are reliably poor shooters based on changes in particular features such as shot distance. An NBA center will struggle to shoot long range shots, therefore when shot distance increases, our classifier is quite accurate in predicting the outcome.&lt;/p&gt;

&lt;p&gt;This project is also reproducible through &lt;code&gt;docker&lt;/code&gt;. Inside the repository linked below, you will find a dockerfile with instructions for running all of the scripts with their respective dependencies (R and python libraries). If you don&amp;rsquo;t have all of the dependencies installed locally that&amp;rsquo;s ok, just use the dockerfile written to run the scripts in the container provided.&lt;/p&gt;

&lt;p&gt;For easily reproducing and generating data regarding NBA players, this project uses &lt;code&gt;make&lt;/code&gt; to run multiple scripts in terminal as well. If interested, you can find the repository on my github account &lt;a href=&#34;https://github.com/ehhope/LBJ-for-Tree&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; with instructions in the README file for using these tools.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
